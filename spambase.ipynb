{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hthelander/Project-4/blob/main/spambase.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "gEaalHwsf-ih"
      },
      "outputs": [],
      "source": [
        "#dependencies\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#read csv file\n",
        "spambase_df=pd.read_csv(\"../content/sample_data/spamcsv.csv.csv\")\n",
        "spambase_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "LisTXY2nhTpL",
<<<<<<< HEAD
        "outputId": "c6958622-7ace-4620-9fa1-d7358e0979aa"
=======
        "outputId": "ba19e14b-52e8-4d63-8bd5-e16418c9dade"
>>>>>>> f3d0135c0960ed2272d2c7f47d9c9ed29bcb148c
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   word_freq_make  word_freq_address  word_freq_all  word_freq_3d  \\\n",
              "0            0.00               0.64           0.64           0.0   \n",
              "1            0.21               0.28           0.50           0.0   \n",
              "2            0.06               0.00           0.71           0.0   \n",
              "3            0.00               0.00           0.00           0.0   \n",
              "4            0.00               0.00           0.00           0.0   \n",
              "\n",
              "   word_freq_our  word_freq_over  word_freq_remove  word_freq_internet  \\\n",
              "0           0.32            0.00              0.00                0.00   \n",
              "1           0.14            0.28              0.21                0.07   \n",
              "2           1.23            0.19              0.19                0.12   \n",
              "3           0.63            0.00              0.31                0.63   \n",
              "4           0.63            0.00              0.31                0.63   \n",
              "\n",
              "   word_freq_order  word_freq_mail  ...  char_freq_%3B  char_freq_%28  \\\n",
              "0             0.00            0.00  ...           0.00          0.000   \n",
              "1             0.00            0.94  ...           0.00          0.132   \n",
              "2             0.64            0.25  ...           0.01          0.143   \n",
              "3             0.31            0.63  ...           0.00          0.137   \n",
              "4             0.31            0.63  ...           0.00          0.135   \n",
              "\n",
              "   char_freq_%5B  char_freq_%21  char_freq_%24  char_freq_%23  \\\n",
              "0            0.0          0.778          0.000          0.000   \n",
              "1            0.0          0.372          0.180          0.048   \n",
              "2            0.0          0.276          0.184          0.010   \n",
              "3            0.0          0.137          0.000          0.000   \n",
              "4            0.0          0.135          0.000          0.000   \n",
              "\n",
              "   capital_run_length_average  capital_run_length_longest  \\\n",
              "0                       3.756                          61   \n",
              "1                       5.114                         101   \n",
              "2                       9.821                         485   \n",
              "3                       3.537                          40   \n",
              "4                       3.537                          40   \n",
              "\n",
              "   capital_run_length_total  class  \n",
              "0                       278      1  \n",
              "1                      1028      1  \n",
              "2                      2259      1  \n",
              "3                       191      1  \n",
              "4                       191      1  \n",
              "\n",
              "[5 rows x 58 columns]"
            ],
            "text/html": [
              "\n",
<<<<<<< HEAD
              "  <div id=\"df-6b051b0b-870c-4f09-a4bf-de23afe48a12\">\n",
=======
              "  <div id=\"df-63e0c825-87a5-4c03-b8aa-1728dead0c4b\">\n",
>>>>>>> f3d0135c0960ed2272d2c7f47d9c9ed29bcb148c
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>word_freq_make</th>\n",
              "      <th>word_freq_address</th>\n",
              "      <th>word_freq_all</th>\n",
              "      <th>word_freq_3d</th>\n",
              "      <th>word_freq_our</th>\n",
              "      <th>word_freq_over</th>\n",
              "      <th>word_freq_remove</th>\n",
              "      <th>word_freq_internet</th>\n",
              "      <th>word_freq_order</th>\n",
              "      <th>word_freq_mail</th>\n",
              "      <th>...</th>\n",
              "      <th>char_freq_%3B</th>\n",
              "      <th>char_freq_%28</th>\n",
              "      <th>char_freq_%5B</th>\n",
              "      <th>char_freq_%21</th>\n",
              "      <th>char_freq_%24</th>\n",
              "      <th>char_freq_%23</th>\n",
              "      <th>capital_run_length_average</th>\n",
              "      <th>capital_run_length_longest</th>\n",
              "      <th>capital_run_length_total</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.64</td>\n",
              "      <td>0.64</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.32</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>...</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.778</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>3.756</td>\n",
              "      <td>61</td>\n",
              "      <td>278</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.21</td>\n",
              "      <td>0.28</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.28</td>\n",
              "      <td>0.21</td>\n",
              "      <td>0.07</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.94</td>\n",
              "      <td>...</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.132</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.372</td>\n",
              "      <td>0.180</td>\n",
              "      <td>0.048</td>\n",
              "      <td>5.114</td>\n",
              "      <td>101</td>\n",
              "      <td>1028</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.06</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.71</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.23</td>\n",
              "      <td>0.19</td>\n",
              "      <td>0.19</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.64</td>\n",
              "      <td>0.25</td>\n",
              "      <td>...</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.143</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.276</td>\n",
              "      <td>0.184</td>\n",
              "      <td>0.010</td>\n",
              "      <td>9.821</td>\n",
              "      <td>485</td>\n",
              "      <td>2259</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.63</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.63</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.63</td>\n",
              "      <td>...</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.137</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.137</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>3.537</td>\n",
              "      <td>40</td>\n",
              "      <td>191</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.63</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.63</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.63</td>\n",
              "      <td>...</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.135</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.135</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>3.537</td>\n",
              "      <td>40</td>\n",
              "      <td>191</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 58 columns</p>\n",
              "</div>\n",
<<<<<<< HEAD
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6b051b0b-870c-4f09-a4bf-de23afe48a12')\"\n",
=======
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-63e0c825-87a5-4c03-b8aa-1728dead0c4b')\"\n",
>>>>>>> f3d0135c0960ed2272d2c7f47d9c9ed29bcb148c
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
<<<<<<< HEAD
              "          document.querySelector('#df-6b051b0b-870c-4f09-a4bf-de23afe48a12 button.colab-df-convert');\n",
=======
              "          document.querySelector('#df-63e0c825-87a5-4c03-b8aa-1728dead0c4b button.colab-df-convert');\n",
>>>>>>> f3d0135c0960ed2272d2c7f47d9c9ed29bcb148c
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
<<<<<<< HEAD
              "          const element = document.querySelector('#df-6b051b0b-870c-4f09-a4bf-de23afe48a12');\n",
=======
              "          const element = document.querySelector('#df-63e0c825-87a5-4c03-b8aa-1728dead0c4b');\n",
>>>>>>> f3d0135c0960ed2272d2c7f47d9c9ed29bcb148c
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word_counts=spambase_df[\"class\"]\n",
        "word_counts"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jNybD7XOhT4I",
<<<<<<< HEAD
        "outputId": "aad80eca-4db7-4f3e-8e9f-0f0757a22d86"
=======
        "outputId": "f7ed03d4-0403-493a-e9c1-ba6772941b6a"
>>>>>>> f3d0135c0960ed2272d2c7f47d9c9ed29bcb148c
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       1\n",
              "1       1\n",
              "2       1\n",
              "3       1\n",
              "4       1\n",
              "       ..\n",
              "4596    0\n",
              "4597    0\n",
              "4598    0\n",
              "4599    0\n",
              "4600    0\n",
              "Name: class, Length: 4601, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spambase_df.drop_duplicates(keep='last')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "-umH0WayfM-e",
<<<<<<< HEAD
        "outputId": "8953683f-9bcd-4977-a1f8-b50dc1fe161d"
=======
        "outputId": "3a7e1933-2acd-4bf9-f1f7-46f53630e80d"
>>>>>>> f3d0135c0960ed2272d2c7f47d9c9ed29bcb148c
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      word_freq_make  word_freq_address  word_freq_all  word_freq_3d  \\\n",
              "0               0.00               0.64           0.64           0.0   \n",
              "1               0.21               0.28           0.50           0.0   \n",
              "2               0.06               0.00           0.71           0.0   \n",
              "3               0.00               0.00           0.00           0.0   \n",
              "4               0.00               0.00           0.00           0.0   \n",
              "...              ...                ...            ...           ...   \n",
              "4596            0.31               0.00           0.62           0.0   \n",
              "4597            0.00               0.00           0.00           0.0   \n",
              "4598            0.30               0.00           0.30           0.0   \n",
              "4599            0.96               0.00           0.00           0.0   \n",
              "4600            0.00               0.00           0.65           0.0   \n",
              "\n",
              "      word_freq_our  word_freq_over  word_freq_remove  word_freq_internet  \\\n",
              "0              0.32            0.00              0.00                0.00   \n",
              "1              0.14            0.28              0.21                0.07   \n",
              "2              1.23            0.19              0.19                0.12   \n",
              "3              0.63            0.00              0.31                0.63   \n",
              "4              0.63            0.00              0.31                0.63   \n",
              "...             ...             ...               ...                 ...   \n",
              "4596           0.00            0.31              0.00                0.00   \n",
              "4597           0.00            0.00              0.00                0.00   \n",
              "4598           0.00            0.00              0.00                0.00   \n",
              "4599           0.32            0.00              0.00                0.00   \n",
              "4600           0.00            0.00              0.00                0.00   \n",
              "\n",
              "      word_freq_order  word_freq_mail  ...  char_freq_%3B  char_freq_%28  \\\n",
              "0                0.00            0.00  ...          0.000          0.000   \n",
              "1                0.00            0.94  ...          0.000          0.132   \n",
              "2                0.64            0.25  ...          0.010          0.143   \n",
              "3                0.31            0.63  ...          0.000          0.137   \n",
              "4                0.31            0.63  ...          0.000          0.135   \n",
              "...               ...             ...  ...            ...            ...   \n",
              "4596             0.00            0.00  ...          0.000          0.232   \n",
              "4597             0.00            0.00  ...          0.000          0.000   \n",
              "4598             0.00            0.00  ...          0.102          0.718   \n",
              "4599             0.00            0.00  ...          0.000          0.057   \n",
              "4600             0.00            0.00  ...          0.000          0.000   \n",
              "\n",
              "      char_freq_%5B  char_freq_%21  char_freq_%24  char_freq_%23  \\\n",
              "0               0.0          0.778          0.000          0.000   \n",
              "1               0.0          0.372          0.180          0.048   \n",
              "2               0.0          0.276          0.184          0.010   \n",
              "3               0.0          0.137          0.000          0.000   \n",
              "4               0.0          0.135          0.000          0.000   \n",
              "...             ...            ...            ...            ...   \n",
              "4596            0.0          0.000          0.000          0.000   \n",
              "4597            0.0          0.353          0.000          0.000   \n",
              "4598            0.0          0.000          0.000          0.000   \n",
              "4599            0.0          0.000          0.000          0.000   \n",
              "4600            0.0          0.125          0.000          0.000   \n",
              "\n",
              "      capital_run_length_average  capital_run_length_longest  \\\n",
              "0                          3.756                          61   \n",
              "1                          5.114                         101   \n",
              "2                          9.821                         485   \n",
              "3                          3.537                          40   \n",
              "4                          3.537                          40   \n",
              "...                          ...                         ...   \n",
              "4596                       1.142                           3   \n",
              "4597                       1.555                           4   \n",
              "4598                       1.404                           6   \n",
              "4599                       1.147                           5   \n",
              "4600                       1.250                           5   \n",
              "\n",
              "      capital_run_length_total  class  \n",
              "0                          278      1  \n",
              "1                         1028      1  \n",
              "2                         2259      1  \n",
              "3                          191      1  \n",
              "4                          191      1  \n",
              "...                        ...    ...  \n",
              "4596                        88      0  \n",
              "4597                        14      0  \n",
              "4598                       118      0  \n",
              "4599                        78      0  \n",
              "4600                        40      0  \n",
              "\n",
              "[4210 rows x 58 columns]"
            ],
            "text/html": [
              "\n",
<<<<<<< HEAD
              "  <div id=\"df-b221f02c-b922-44b1-9f25-79493b2ce779\">\n",
=======
              "  <div id=\"df-849ddbd0-f6fe-43ac-bc31-a986834af528\">\n",
>>>>>>> f3d0135c0960ed2272d2c7f47d9c9ed29bcb148c
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>word_freq_make</th>\n",
              "      <th>word_freq_address</th>\n",
              "      <th>word_freq_all</th>\n",
              "      <th>word_freq_3d</th>\n",
              "      <th>word_freq_our</th>\n",
              "      <th>word_freq_over</th>\n",
              "      <th>word_freq_remove</th>\n",
              "      <th>word_freq_internet</th>\n",
              "      <th>word_freq_order</th>\n",
              "      <th>word_freq_mail</th>\n",
              "      <th>...</th>\n",
              "      <th>char_freq_%3B</th>\n",
              "      <th>char_freq_%28</th>\n",
              "      <th>char_freq_%5B</th>\n",
              "      <th>char_freq_%21</th>\n",
              "      <th>char_freq_%24</th>\n",
              "      <th>char_freq_%23</th>\n",
              "      <th>capital_run_length_average</th>\n",
              "      <th>capital_run_length_longest</th>\n",
              "      <th>capital_run_length_total</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.64</td>\n",
              "      <td>0.64</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.32</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.778</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>3.756</td>\n",
              "      <td>61</td>\n",
              "      <td>278</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.21</td>\n",
              "      <td>0.28</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.28</td>\n",
              "      <td>0.21</td>\n",
              "      <td>0.07</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.94</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.132</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.372</td>\n",
              "      <td>0.180</td>\n",
              "      <td>0.048</td>\n",
              "      <td>5.114</td>\n",
              "      <td>101</td>\n",
              "      <td>1028</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.06</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.71</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.23</td>\n",
              "      <td>0.19</td>\n",
              "      <td>0.19</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.64</td>\n",
              "      <td>0.25</td>\n",
              "      <td>...</td>\n",
              "      <td>0.010</td>\n",
              "      <td>0.143</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.276</td>\n",
              "      <td>0.184</td>\n",
              "      <td>0.010</td>\n",
              "      <td>9.821</td>\n",
              "      <td>485</td>\n",
              "      <td>2259</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.63</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.63</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.63</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.137</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.137</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>3.537</td>\n",
              "      <td>40</td>\n",
              "      <td>191</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.63</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.63</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.63</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.135</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.135</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>3.537</td>\n",
              "      <td>40</td>\n",
              "      <td>191</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4596</th>\n",
              "      <td>0.31</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.62</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.232</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1.142</td>\n",
              "      <td>3</td>\n",
              "      <td>88</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4597</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.353</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1.555</td>\n",
              "      <td>4</td>\n",
              "      <td>14</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4598</th>\n",
              "      <td>0.30</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.30</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>...</td>\n",
              "      <td>0.102</td>\n",
              "      <td>0.718</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1.404</td>\n",
              "      <td>6</td>\n",
              "      <td>118</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4599</th>\n",
              "      <td>0.96</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.32</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.057</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1.147</td>\n",
              "      <td>5</td>\n",
              "      <td>78</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4600</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.65</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.125</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1.250</td>\n",
              "      <td>5</td>\n",
              "      <td>40</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4210 rows × 58 columns</p>\n",
              "</div>\n",
<<<<<<< HEAD
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b221f02c-b922-44b1-9f25-79493b2ce779')\"\n",
=======
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-849ddbd0-f6fe-43ac-bc31-a986834af528')\"\n",
>>>>>>> f3d0135c0960ed2272d2c7f47d9c9ed29bcb148c
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
<<<<<<< HEAD
              "          document.querySelector('#df-b221f02c-b922-44b1-9f25-79493b2ce779 button.colab-df-convert');\n",
=======
              "          document.querySelector('#df-849ddbd0-f6fe-43ac-bc31-a986834af528 button.colab-df-convert');\n",
>>>>>>> f3d0135c0960ed2272d2c7f47d9c9ed29bcb148c
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
<<<<<<< HEAD
              "          const element = document.querySelector('#df-b221f02c-b922-44b1-9f25-79493b2ce779');\n",
=======
              "          const element = document.querySelector('#df-849ddbd0-f6fe-43ac-bc31-a986834af528');\n",
>>>>>>> f3d0135c0960ed2272d2c7f47d9c9ed29bcb148c
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spambase_df.describe"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7jVo-rAwuQ4t",
<<<<<<< HEAD
        "outputId": "8af2a97e-86e6-4623-9d0f-eb109856ee38"
=======
        "outputId": "e1b2b403-a5c8-453f-bf36-950b2373fc09"
>>>>>>> f3d0135c0960ed2272d2c7f47d9c9ed29bcb148c
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method NDFrame.describe of       word_freq_make  word_freq_address  word_freq_all  word_freq_3d  \\\n",
              "0               0.00               0.64           0.64           0.0   \n",
              "1               0.21               0.28           0.50           0.0   \n",
              "2               0.06               0.00           0.71           0.0   \n",
              "3               0.00               0.00           0.00           0.0   \n",
              "4               0.00               0.00           0.00           0.0   \n",
              "...              ...                ...            ...           ...   \n",
              "4596            0.31               0.00           0.62           0.0   \n",
              "4597            0.00               0.00           0.00           0.0   \n",
              "4598            0.30               0.00           0.30           0.0   \n",
              "4599            0.96               0.00           0.00           0.0   \n",
              "4600            0.00               0.00           0.65           0.0   \n",
              "\n",
              "      word_freq_our  word_freq_over  word_freq_remove  word_freq_internet  \\\n",
              "0              0.32            0.00              0.00                0.00   \n",
              "1              0.14            0.28              0.21                0.07   \n",
              "2              1.23            0.19              0.19                0.12   \n",
              "3              0.63            0.00              0.31                0.63   \n",
              "4              0.63            0.00              0.31                0.63   \n",
              "...             ...             ...               ...                 ...   \n",
              "4596           0.00            0.31              0.00                0.00   \n",
              "4597           0.00            0.00              0.00                0.00   \n",
              "4598           0.00            0.00              0.00                0.00   \n",
              "4599           0.32            0.00              0.00                0.00   \n",
              "4600           0.00            0.00              0.00                0.00   \n",
              "\n",
              "      word_freq_order  word_freq_mail  ...  char_freq_%3B  char_freq_%28  \\\n",
              "0                0.00            0.00  ...          0.000          0.000   \n",
              "1                0.00            0.94  ...          0.000          0.132   \n",
              "2                0.64            0.25  ...          0.010          0.143   \n",
              "3                0.31            0.63  ...          0.000          0.137   \n",
              "4                0.31            0.63  ...          0.000          0.135   \n",
              "...               ...             ...  ...            ...            ...   \n",
              "4596             0.00            0.00  ...          0.000          0.232   \n",
              "4597             0.00            0.00  ...          0.000          0.000   \n",
              "4598             0.00            0.00  ...          0.102          0.718   \n",
              "4599             0.00            0.00  ...          0.000          0.057   \n",
              "4600             0.00            0.00  ...          0.000          0.000   \n",
              "\n",
              "      char_freq_%5B  char_freq_%21  char_freq_%24  char_freq_%23  \\\n",
              "0               0.0          0.778          0.000          0.000   \n",
              "1               0.0          0.372          0.180          0.048   \n",
              "2               0.0          0.276          0.184          0.010   \n",
              "3               0.0          0.137          0.000          0.000   \n",
              "4               0.0          0.135          0.000          0.000   \n",
              "...             ...            ...            ...            ...   \n",
              "4596            0.0          0.000          0.000          0.000   \n",
              "4597            0.0          0.353          0.000          0.000   \n",
              "4598            0.0          0.000          0.000          0.000   \n",
              "4599            0.0          0.000          0.000          0.000   \n",
              "4600            0.0          0.125          0.000          0.000   \n",
              "\n",
              "      capital_run_length_average  capital_run_length_longest  \\\n",
              "0                          3.756                          61   \n",
              "1                          5.114                         101   \n",
              "2                          9.821                         485   \n",
              "3                          3.537                          40   \n",
              "4                          3.537                          40   \n",
              "...                          ...                         ...   \n",
              "4596                       1.142                           3   \n",
              "4597                       1.555                           4   \n",
              "4598                       1.404                           6   \n",
              "4599                       1.147                           5   \n",
              "4600                       1.250                           5   \n",
              "\n",
              "      capital_run_length_total  class  \n",
              "0                          278      1  \n",
              "1                         1028      1  \n",
              "2                         2259      1  \n",
              "3                          191      1  \n",
              "4                          191      1  \n",
              "...                        ...    ...  \n",
              "4596                        88      0  \n",
              "4597                        14      0  \n",
              "4598                       118      0  \n",
              "4599                        78      0  \n",
              "4600                        40      0  \n",
              "\n",
              "[4601 rows x 58 columns]>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spambase_df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hqBUS9Xkb5Os",
<<<<<<< HEAD
        "outputId": "254ee62e-6eea-4890-c6a4-345190ad337d"
=======
        "outputId": "a108708b-a1ab-42a3-d74c-5922b1ce795f"
>>>>>>> f3d0135c0960ed2272d2c7f47d9c9ed29bcb148c
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 4601 entries, 0 to 4600\n",
            "Data columns (total 58 columns):\n",
            " #   Column                      Non-Null Count  Dtype  \n",
            "---  ------                      --------------  -----  \n",
            " 0   word_freq_make              4601 non-null   float64\n",
            " 1   word_freq_address           4601 non-null   float64\n",
            " 2   word_freq_all               4601 non-null   float64\n",
            " 3   word_freq_3d                4601 non-null   float64\n",
            " 4   word_freq_our               4601 non-null   float64\n",
            " 5   word_freq_over              4601 non-null   float64\n",
            " 6   word_freq_remove            4601 non-null   float64\n",
            " 7   word_freq_internet          4601 non-null   float64\n",
            " 8   word_freq_order             4601 non-null   float64\n",
            " 9   word_freq_mail              4601 non-null   float64\n",
            " 10  word_freq_receive           4601 non-null   float64\n",
            " 11  word_freq_will              4601 non-null   float64\n",
            " 12  word_freq_people            4601 non-null   float64\n",
            " 13  word_freq_report            4601 non-null   float64\n",
            " 14  word_freq_addresses         4601 non-null   float64\n",
            " 15  word_freq_free              4601 non-null   float64\n",
            " 16  word_freq_business          4601 non-null   float64\n",
            " 17  word_freq_email             4601 non-null   float64\n",
            " 18  word_freq_you               4601 non-null   float64\n",
            " 19  word_freq_credit            4601 non-null   float64\n",
            " 20  word_freq_your              4601 non-null   float64\n",
            " 21  word_freq_font              4601 non-null   float64\n",
            " 22  word_freq_000               4601 non-null   float64\n",
            " 23  word_freq_money             4601 non-null   float64\n",
            " 24  word_freq_hp                4601 non-null   float64\n",
            " 25  word_freq_hpl               4601 non-null   float64\n",
            " 26  word_freq_george            4601 non-null   float64\n",
            " 27  word_freq_650               4601 non-null   float64\n",
            " 28  word_freq_lab               4601 non-null   float64\n",
            " 29  word_freq_labs              4601 non-null   float64\n",
            " 30  word_freq_telnet            4601 non-null   float64\n",
            " 31  word_freq_857               4601 non-null   float64\n",
            " 32  word_freq_data              4601 non-null   float64\n",
            " 33  word_freq_415               4601 non-null   float64\n",
            " 34  word_freq_85                4601 non-null   float64\n",
            " 35  word_freq_technology        4601 non-null   float64\n",
            " 36  word_freq_1999              4601 non-null   float64\n",
            " 37  word_freq_parts             4601 non-null   float64\n",
            " 38  word_freq_pm                4601 non-null   float64\n",
            " 39  word_freq_direct            4601 non-null   float64\n",
            " 40  word_freq_cs                4601 non-null   float64\n",
            " 41  word_freq_meeting           4601 non-null   float64\n",
            " 42  word_freq_original          4601 non-null   float64\n",
            " 43  word_freq_project           4601 non-null   float64\n",
            " 44  word_freq_re                4601 non-null   float64\n",
            " 45  word_freq_edu               4601 non-null   float64\n",
            " 46  word_freq_table             4601 non-null   float64\n",
            " 47  word_freq_conference        4601 non-null   float64\n",
            " 48  char_freq_%3B               4601 non-null   float64\n",
            " 49  char_freq_%28               4601 non-null   float64\n",
            " 50  char_freq_%5B               4601 non-null   float64\n",
            " 51  char_freq_%21               4601 non-null   float64\n",
            " 52  char_freq_%24               4601 non-null   float64\n",
            " 53  char_freq_%23               4601 non-null   float64\n",
            " 54  capital_run_length_average  4601 non-null   float64\n",
            " 55  capital_run_length_longest  4601 non-null   int64  \n",
            " 56  capital_run_length_total    4601 non-null   int64  \n",
            " 57  class                       4601 non-null   int64  \n",
            "dtypes: float64(55), int64(3)\n",
            "memory usage: 2.0 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "display(spambase_df.describe())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "id": "wwgvwL64colW",
<<<<<<< HEAD
        "outputId": "f0989402-5fb7-40b8-c75e-4e4c0ab86360"
=======
        "outputId": "218c4af9-3458-4016-c332-f75c030449eb"
>>>>>>> f3d0135c0960ed2272d2c7f47d9c9ed29bcb148c
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "       word_freq_make  word_freq_address  word_freq_all  word_freq_3d  \\\n",
              "count     4601.000000        4601.000000    4601.000000   4601.000000   \n",
              "mean         0.104553           0.213015       0.280656      0.065425   \n",
              "std          0.305358           1.290575       0.504143      1.395151   \n",
              "min          0.000000           0.000000       0.000000      0.000000   \n",
              "25%          0.000000           0.000000       0.000000      0.000000   \n",
              "50%          0.000000           0.000000       0.000000      0.000000   \n",
              "75%          0.000000           0.000000       0.420000      0.000000   \n",
              "max          4.540000          14.280000       5.100000     42.810000   \n",
              "\n",
              "       word_freq_our  word_freq_over  word_freq_remove  word_freq_internet  \\\n",
              "count    4601.000000     4601.000000       4601.000000         4601.000000   \n",
              "mean        0.312223        0.095901          0.114208            0.105295   \n",
              "std         0.672513        0.273824          0.391441            0.401071   \n",
              "min         0.000000        0.000000          0.000000            0.000000   \n",
              "25%         0.000000        0.000000          0.000000            0.000000   \n",
              "50%         0.000000        0.000000          0.000000            0.000000   \n",
              "75%         0.380000        0.000000          0.000000            0.000000   \n",
              "max        10.000000        5.880000          7.270000           11.110000   \n",
              "\n",
              "       word_freq_order  word_freq_mail  ...  char_freq_%3B  char_freq_%28  \\\n",
              "count      4601.000000     4601.000000  ...    4601.000000    4601.000000   \n",
              "mean          0.090067        0.239413  ...       0.038575       0.139030   \n",
              "std           0.278616        0.644755  ...       0.243471       0.270355   \n",
              "min           0.000000        0.000000  ...       0.000000       0.000000   \n",
              "25%           0.000000        0.000000  ...       0.000000       0.000000   \n",
              "50%           0.000000        0.000000  ...       0.000000       0.065000   \n",
              "75%           0.000000        0.160000  ...       0.000000       0.188000   \n",
              "max           5.260000       18.180000  ...       4.385000       9.752000   \n",
              "\n",
              "       char_freq_%5B  char_freq_%21  char_freq_%24  char_freq_%23  \\\n",
              "count    4601.000000    4601.000000    4601.000000    4601.000000   \n",
              "mean        0.016976       0.269071       0.075811       0.044238   \n",
              "std         0.109394       0.815672       0.245882       0.429342   \n",
              "min         0.000000       0.000000       0.000000       0.000000   \n",
              "25%         0.000000       0.000000       0.000000       0.000000   \n",
              "50%         0.000000       0.000000       0.000000       0.000000   \n",
              "75%         0.000000       0.315000       0.052000       0.000000   \n",
              "max         4.081000      32.478000       6.003000      19.829000   \n",
              "\n",
              "       capital_run_length_average  capital_run_length_longest  \\\n",
              "count                 4601.000000                 4601.000000   \n",
              "mean                     5.191515                   52.172789   \n",
              "std                     31.729449                  194.891310   \n",
              "min                      1.000000                    1.000000   \n",
              "25%                      1.588000                    6.000000   \n",
              "50%                      2.276000                   15.000000   \n",
              "75%                      3.706000                   43.000000   \n",
              "max                   1102.500000                 9989.000000   \n",
              "\n",
              "       capital_run_length_total        class  \n",
              "count               4601.000000  4601.000000  \n",
              "mean                 283.289285     0.394045  \n",
              "std                  606.347851     0.488698  \n",
              "min                    1.000000     0.000000  \n",
              "25%                   35.000000     0.000000  \n",
              "50%                   95.000000     0.000000  \n",
              "75%                  266.000000     1.000000  \n",
              "max                15841.000000     1.000000  \n",
              "\n",
              "[8 rows x 58 columns]"
            ],
            "text/html": [
              "\n",
<<<<<<< HEAD
              "  <div id=\"df-0433b59c-9168-4b70-8e78-495101b9a269\">\n",
=======
              "  <div id=\"df-e7a92a07-7fc3-44ac-bdae-14126a95db58\">\n",
>>>>>>> f3d0135c0960ed2272d2c7f47d9c9ed29bcb148c
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>word_freq_make</th>\n",
              "      <th>word_freq_address</th>\n",
              "      <th>word_freq_all</th>\n",
              "      <th>word_freq_3d</th>\n",
              "      <th>word_freq_our</th>\n",
              "      <th>word_freq_over</th>\n",
              "      <th>word_freq_remove</th>\n",
              "      <th>word_freq_internet</th>\n",
              "      <th>word_freq_order</th>\n",
              "      <th>word_freq_mail</th>\n",
              "      <th>...</th>\n",
              "      <th>char_freq_%3B</th>\n",
              "      <th>char_freq_%28</th>\n",
              "      <th>char_freq_%5B</th>\n",
              "      <th>char_freq_%21</th>\n",
              "      <th>char_freq_%24</th>\n",
              "      <th>char_freq_%23</th>\n",
              "      <th>capital_run_length_average</th>\n",
              "      <th>capital_run_length_longest</th>\n",
              "      <th>capital_run_length_total</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>4601.000000</td>\n",
              "      <td>4601.000000</td>\n",
              "      <td>4601.000000</td>\n",
              "      <td>4601.000000</td>\n",
              "      <td>4601.000000</td>\n",
              "      <td>4601.000000</td>\n",
              "      <td>4601.000000</td>\n",
              "      <td>4601.000000</td>\n",
              "      <td>4601.000000</td>\n",
              "      <td>4601.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>4601.000000</td>\n",
              "      <td>4601.000000</td>\n",
              "      <td>4601.000000</td>\n",
              "      <td>4601.000000</td>\n",
              "      <td>4601.000000</td>\n",
              "      <td>4601.000000</td>\n",
              "      <td>4601.000000</td>\n",
              "      <td>4601.000000</td>\n",
              "      <td>4601.000000</td>\n",
              "      <td>4601.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.104553</td>\n",
              "      <td>0.213015</td>\n",
              "      <td>0.280656</td>\n",
              "      <td>0.065425</td>\n",
              "      <td>0.312223</td>\n",
              "      <td>0.095901</td>\n",
              "      <td>0.114208</td>\n",
              "      <td>0.105295</td>\n",
              "      <td>0.090067</td>\n",
              "      <td>0.239413</td>\n",
              "      <td>...</td>\n",
              "      <td>0.038575</td>\n",
              "      <td>0.139030</td>\n",
              "      <td>0.016976</td>\n",
              "      <td>0.269071</td>\n",
              "      <td>0.075811</td>\n",
              "      <td>0.044238</td>\n",
              "      <td>5.191515</td>\n",
              "      <td>52.172789</td>\n",
              "      <td>283.289285</td>\n",
              "      <td>0.394045</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.305358</td>\n",
              "      <td>1.290575</td>\n",
              "      <td>0.504143</td>\n",
              "      <td>1.395151</td>\n",
              "      <td>0.672513</td>\n",
              "      <td>0.273824</td>\n",
              "      <td>0.391441</td>\n",
              "      <td>0.401071</td>\n",
              "      <td>0.278616</td>\n",
              "      <td>0.644755</td>\n",
              "      <td>...</td>\n",
              "      <td>0.243471</td>\n",
              "      <td>0.270355</td>\n",
              "      <td>0.109394</td>\n",
              "      <td>0.815672</td>\n",
              "      <td>0.245882</td>\n",
              "      <td>0.429342</td>\n",
              "      <td>31.729449</td>\n",
              "      <td>194.891310</td>\n",
              "      <td>606.347851</td>\n",
              "      <td>0.488698</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.588000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>35.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.065000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.276000</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>95.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.420000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.380000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.160000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.188000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.315000</td>\n",
              "      <td>0.052000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.706000</td>\n",
              "      <td>43.000000</td>\n",
              "      <td>266.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>4.540000</td>\n",
              "      <td>14.280000</td>\n",
              "      <td>5.100000</td>\n",
              "      <td>42.810000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>5.880000</td>\n",
              "      <td>7.270000</td>\n",
              "      <td>11.110000</td>\n",
              "      <td>5.260000</td>\n",
              "      <td>18.180000</td>\n",
              "      <td>...</td>\n",
              "      <td>4.385000</td>\n",
              "      <td>9.752000</td>\n",
              "      <td>4.081000</td>\n",
              "      <td>32.478000</td>\n",
              "      <td>6.003000</td>\n",
              "      <td>19.829000</td>\n",
              "      <td>1102.500000</td>\n",
              "      <td>9989.000000</td>\n",
              "      <td>15841.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows × 58 columns</p>\n",
              "</div>\n",
<<<<<<< HEAD
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0433b59c-9168-4b70-8e78-495101b9a269')\"\n",
=======
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e7a92a07-7fc3-44ac-bdae-14126a95db58')\"\n",
>>>>>>> f3d0135c0960ed2272d2c7f47d9c9ed29bcb148c
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
<<<<<<< HEAD
              "          document.querySelector('#df-0433b59c-9168-4b70-8e78-495101b9a269 button.colab-df-convert');\n",
=======
              "          document.querySelector('#df-e7a92a07-7fc3-44ac-bdae-14126a95db58 button.colab-df-convert');\n",
>>>>>>> f3d0135c0960ed2272d2c7f47d9c9ed29bcb148c
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
<<<<<<< HEAD
              "          const element = document.querySelector('#df-0433b59c-9168-4b70-8e78-495101b9a269');\n",
=======
              "          const element = document.querySelector('#df-e7a92a07-7fc3-44ac-bdae-14126a95db58');\n",
>>>>>>> f3d0135c0960ed2272d2c7f47d9c9ed29bcb148c
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split our preprocessed data into our features and target arrays\n",
        "X=spambase_df.drop(\"class\",axis=1).values\n",
        "y=spambase_df[\"class\"].values"
      ],
      "metadata": {
        "id": "n-I6oJIrhT6-"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the preprocessed data into a training and testing dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 42)\n",
        "     "
      ],
      "metadata": {
        "id": "6M5A66j2jlI7"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#create a standardscaler instances\n",
        "scaler=StandardScaler()\n",
        "#fit the standard scaler\n",
        "X_scaler=scaler.fit(X_train)\n",
        "# Scale the data\n",
        "X_train_scaled = X_scaler.transform(X_train)\n",
        "X_test_scaled = X_scaler.transform(X_test)\n",
        "     "
      ],
      "metadata": {
        "id": "ifvx_03ohT-S"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compile, Train and Evaluate the Model\n"
      ],
      "metadata": {
        "id": "MCCXS_3Pj5mF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the input feature/ shape\n",
        "X_train_scaled.shape\n",
        "     "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pmzB-vqqj3Ju",
<<<<<<< HEAD
        "outputId": "bcc07334-d662-4e6d-f108-88a3d7d136be"
=======
        "outputId": "57a03743-ffdb-47fc-b379-b70186ee5f11"
>>>>>>> f3d0135c0960ed2272d2c7f47d9c9ed29bcb148c
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3450, 57)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Neural network optimization\n"
      ],
      "metadata": {
        "id": "SToZG4TokFrP"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_Azn8Oo3s3Xp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keras-tuner\n",
        "     "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HBvqGAE6j28J",
<<<<<<< HEAD
        "outputId": "ac3d83d9-0075-42b0-e20a-7e58deef3f8f"
=======
        "outputId": "d74a45f9-a3a0-423b-acc1-abce5e97e150"
>>>>>>> f3d0135c0960ed2272d2c7f47d9c9ed29bcb148c
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting keras-tuner\n",
            "  Downloading keras_tuner-1.3.0-py3-none-any.whl (167 kB)\n",
<<<<<<< HEAD
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.3/167.3 KB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
=======
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.3/167.3 KB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
>>>>>>> f3d0135c0960ed2272d2c7f47d9c9ed29bcb148c
            "\u001b[?25hRequirement already satisfied: tensorflow>=2.0 in /usr/local/lib/python3.8/dist-packages (from keras-tuner) (2.11.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from keras-tuner) (23.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from keras-tuner) (2.25.1)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.8/dist-packages (from keras-tuner) (7.9.0)\n",
            "Collecting kt-legacy\n",
            "  Downloading kt_legacy-1.0.4-py3-none-any.whl (9.6 kB)\n",
<<<<<<< HEAD
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from keras-tuner) (2.25.1)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.8/dist-packages (from keras-tuner) (7.9.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (3.1.0)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (0.4.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.12,>=2.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (2.11.0)\n",
            "Requirement already satisfied: tensorboard<2.12,>=2.11 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (2.11.2)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (0.2.0)\n",
            "Requirement already satisfied: keras<2.12,>=2.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (2.11.0)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (23.1.21)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (15.0.6.1)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (1.22.4)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (1.15.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (1.6.3)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (0.31.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (57.4.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (1.51.3)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (3.3.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (1.15.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (2.2.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (4.5.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (1.4.0)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (3.19.6)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.8/dist-packages (from ipython->keras-tuner) (0.2.0)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.8/dist-packages (from ipython->keras-tuner) (2.6.1)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.8/dist-packages (from ipython->keras-tuner) (0.7.5)\n",
            "Collecting jedi>=0.10\n",
            "  Downloading jedi-0.18.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m29.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: prompt-toolkit<2.1.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from ipython->keras-tuner) (2.0.10)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.8/dist-packages (from ipython->keras-tuner) (4.8.0)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.8/dist-packages (from ipython->keras-tuner) (5.7.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.8/dist-packages (from ipython->keras-tuner) (4.4.2)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->keras-tuner) (2.10)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->keras-tuner) (4.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->keras-tuner) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->keras-tuner) (1.26.14)\n",
=======
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (1.51.3)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (0.31.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (0.2.0)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (0.4.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (57.4.0)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (1.22.4)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (1.6.3)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (15.0.6.1)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (23.1.21)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (1.4.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (2.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (3.1.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.12,>=2.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (2.11.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (1.15.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (4.5.0)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (3.19.6)\n",
            "Requirement already satisfied: keras<2.12,>=2.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (2.11.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (1.15.0)\n",
            "Requirement already satisfied: tensorboard<2.12,>=2.11 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (2.11.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (3.3.0)\n",
            "Requirement already satisfied: prompt-toolkit<2.1.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from ipython->keras-tuner) (2.0.10)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.8/dist-packages (from ipython->keras-tuner) (4.8.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.8/dist-packages (from ipython->keras-tuner) (0.2.0)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.8/dist-packages (from ipython->keras-tuner) (2.6.1)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.8/dist-packages (from ipython->keras-tuner) (0.7.5)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.8/dist-packages (from ipython->keras-tuner) (4.4.2)\n",
            "Collecting jedi>=0.10\n",
            "  Downloading jedi-0.18.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m44.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.8/dist-packages (from ipython->keras-tuner) (5.7.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->keras-tuner) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->keras-tuner) (1.26.14)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->keras-tuner) (4.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->keras-tuner) (2.10)\n",
>>>>>>> f3d0135c0960ed2272d2c7f47d9c9ed29bcb148c
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.8/dist-packages (from astunparse>=1.6.0->tensorflow>=2.0->keras-tuner) (0.38.4)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.8/dist-packages (from jedi>=0.10->ipython->keras-tuner) (0.8.3)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.8/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython->keras-tuner) (0.2.6)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow>=2.0->keras-tuner) (3.4.1)\n",
<<<<<<< HEAD
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow>=2.0->keras-tuner) (0.6.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow>=2.0->keras-tuner) (1.8.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow>=2.0->keras-tuner) (2.16.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow>=2.0->keras-tuner) (2.2.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow>=2.0->keras-tuner) (0.4.6)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.8/dist-packages (from pexpect->ipython->keras-tuner) (0.7.0)\n",
=======
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow>=2.0->keras-tuner) (2.16.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow>=2.0->keras-tuner) (0.6.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow>=2.0->keras-tuner) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow>=2.0->keras-tuner) (2.2.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow>=2.0->keras-tuner) (0.4.6)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.8/dist-packages (from pexpect->ipython->keras-tuner) (0.7.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow>=2.0->keras-tuner) (4.9)\n",
>>>>>>> f3d0135c0960ed2272d2c7f47d9c9ed29bcb148c
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow>=2.0->keras-tuner) (0.2.8)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow>=2.0->keras-tuner) (5.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow>=2.0->keras-tuner) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow>=2.0->keras-tuner) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.8/dist-packages (from markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow>=2.0->keras-tuner) (6.0.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.8/dist-packages (from werkzeug>=1.0.1->tensorboard<2.12,>=2.11->tensorflow>=2.0->keras-tuner) (2.1.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow>=2.0->keras-tuner) (3.15.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow>=2.0->keras-tuner) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow>=2.0->keras-tuner) (3.2.2)\n",
            "Installing collected packages: kt-legacy, jedi, keras-tuner\n",
            "Successfully installed jedi-0.18.2 keras-tuner-1.3.0 kt-legacy-1.0.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nn_model1 = tf.keras.models.Sequential()\n",
        "input_features = X_train_scaled.shape[1]\n",
        "\n",
        "# First hidden layer\n",
        "nn_model1.add(tf.keras.layers.Dense(units=10, activation='relu', input_dim=input_features))\n",
        "\n",
        "# Second hidden layer\n",
        "nn_model1.add(tf.keras.layers.Dense(units=10, activation='relu'))\n",
        "\n",
        "# Output layer\n",
        "\n",
        "nn_model1.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))\n",
        "# Check the structure of the model\n",
        "nn_model1.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j9FKRwDQkOTI",
<<<<<<< HEAD
        "outputId": "3bb68caf-2523-4c7b-8e9e-20ba08f46473"
=======
        "outputId": "f5913903-ca13-49cd-b486-87967c5610b6"
>>>>>>> f3d0135c0960ed2272d2c7f47d9c9ed29bcb148c
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 10)                580       \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                110       \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1)                 11        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 701\n",
            "Trainable params: 701\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "nn_model1.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "aZCS9ezskOPi"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "\n",
        "fit_model_1 = nn_model1.fit(X_train_scaled, y_train, epochs=50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n393T84jkON0",
<<<<<<< HEAD
        "outputId": "ddf2ceba-c92e-441d-dd0b-1c8adc4b5b89"
=======
        "outputId": "012f9078-697e-4674-ea13-913b4ebed9c1"
>>>>>>> f3d0135c0960ed2272d2c7f47d9c9ed29bcb148c
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
<<<<<<< HEAD
            "108/108 [==============================] - 3s 7ms/step - loss: 0.5755 - accuracy: 0.7165\n",
            "Epoch 2/50\n",
            "108/108 [==============================] - 1s 5ms/step - loss: 0.3843 - accuracy: 0.8623\n",
            "Epoch 3/50\n",
            "108/108 [==============================] - 1s 5ms/step - loss: 0.3003 - accuracy: 0.8977\n",
            "Epoch 4/50\n",
            "108/108 [==============================] - 1s 9ms/step - loss: 0.2573 - accuracy: 0.9136\n",
            "Epoch 5/50\n",
            "108/108 [==============================] - 1s 10ms/step - loss: 0.2298 - accuracy: 0.9214\n",
            "Epoch 6/50\n",
            "108/108 [==============================] - 1s 10ms/step - loss: 0.2113 - accuracy: 0.9264\n",
            "Epoch 7/50\n",
            "108/108 [==============================] - 1s 5ms/step - loss: 0.1981 - accuracy: 0.9284\n",
            "Epoch 8/50\n",
            "108/108 [==============================] - 1s 6ms/step - loss: 0.1891 - accuracy: 0.9313\n",
            "Epoch 9/50\n",
            "108/108 [==============================] - 1s 6ms/step - loss: 0.1818 - accuracy: 0.9336\n",
            "Epoch 10/50\n",
            "108/108 [==============================] - 1s 6ms/step - loss: 0.1750 - accuracy: 0.9325\n",
            "Epoch 11/50\n",
            "108/108 [==============================] - 1s 7ms/step - loss: 0.1693 - accuracy: 0.9351\n",
            "Epoch 12/50\n",
            "108/108 [==============================] - 1s 8ms/step - loss: 0.1654 - accuracy: 0.9342\n",
            "Epoch 13/50\n",
            "108/108 [==============================] - 1s 6ms/step - loss: 0.1608 - accuracy: 0.9397\n",
            "Epoch 14/50\n",
            "108/108 [==============================] - 1s 5ms/step - loss: 0.1571 - accuracy: 0.9394\n",
            "Epoch 15/50\n",
            "108/108 [==============================] - 0s 4ms/step - loss: 0.1533 - accuracy: 0.9420\n",
            "Epoch 16/50\n",
            "108/108 [==============================] - 1s 5ms/step - loss: 0.1506 - accuracy: 0.9449\n",
            "Epoch 17/50\n",
            "108/108 [==============================] - 1s 6ms/step - loss: 0.1467 - accuracy: 0.9475\n",
            "Epoch 18/50\n",
            "108/108 [==============================] - 0s 4ms/step - loss: 0.1446 - accuracy: 0.9481\n",
            "Epoch 19/50\n",
            "108/108 [==============================] - 1s 5ms/step - loss: 0.1421 - accuracy: 0.9507\n",
            "Epoch 20/50\n",
            "108/108 [==============================] - 0s 4ms/step - loss: 0.1394 - accuracy: 0.9484\n",
            "Epoch 21/50\n",
            "108/108 [==============================] - 1s 6ms/step - loss: 0.1370 - accuracy: 0.9507\n",
            "Epoch 22/50\n",
            "108/108 [==============================] - 1s 7ms/step - loss: 0.1347 - accuracy: 0.9519\n",
            "Epoch 23/50\n",
            "108/108 [==============================] - 0s 3ms/step - loss: 0.1325 - accuracy: 0.9528\n",
            "Epoch 24/50\n",
            "108/108 [==============================] - 0s 3ms/step - loss: 0.1316 - accuracy: 0.9516\n",
            "Epoch 25/50\n",
            "108/108 [==============================] - 0s 4ms/step - loss: 0.1291 - accuracy: 0.9528\n",
            "Epoch 26/50\n",
            "108/108 [==============================] - 0s 4ms/step - loss: 0.1282 - accuracy: 0.9536\n",
            "Epoch 27/50\n",
            "108/108 [==============================] - 0s 4ms/step - loss: 0.1263 - accuracy: 0.9548\n",
            "Epoch 28/50\n",
            "108/108 [==============================] - 0s 3ms/step - loss: 0.1251 - accuracy: 0.9536\n",
            "Epoch 29/50\n",
            "108/108 [==============================] - 0s 4ms/step - loss: 0.1239 - accuracy: 0.9551\n",
            "Epoch 30/50\n",
            "108/108 [==============================] - 0s 3ms/step - loss: 0.1220 - accuracy: 0.9545\n",
            "Epoch 31/50\n",
            "108/108 [==============================] - 0s 3ms/step - loss: 0.1223 - accuracy: 0.9542\n",
            "Epoch 32/50\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.1195 - accuracy: 0.9559\n",
            "Epoch 33/50\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.1184 - accuracy: 0.9562\n",
            "Epoch 34/50\n",
            "108/108 [==============================] - 0s 3ms/step - loss: 0.1177 - accuracy: 0.9580\n",
            "Epoch 35/50\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.1169 - accuracy: 0.9588\n",
            "Epoch 36/50\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.1157 - accuracy: 0.9588\n",
            "Epoch 37/50\n",
            "108/108 [==============================] - 0s 3ms/step - loss: 0.1160 - accuracy: 0.9574\n",
            "Epoch 38/50\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.1138 - accuracy: 0.9586\n",
            "Epoch 39/50\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.1132 - accuracy: 0.9597\n",
            "Epoch 40/50\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.1130 - accuracy: 0.9591\n",
            "Epoch 41/50\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.1105 - accuracy: 0.9614\n",
            "Epoch 42/50\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.1101 - accuracy: 0.9594\n",
            "Epoch 43/50\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.1090 - accuracy: 0.9586\n",
            "Epoch 44/50\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.1090 - accuracy: 0.9620\n",
            "Epoch 45/50\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.1074 - accuracy: 0.9617\n",
            "Epoch 46/50\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.1077 - accuracy: 0.9603\n",
            "Epoch 47/50\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.1055 - accuracy: 0.9620\n",
            "Epoch 48/50\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.1055 - accuracy: 0.9614\n",
            "Epoch 49/50\n",
            "108/108 [==============================] - 0s 3ms/step - loss: 0.1046 - accuracy: 0.9629\n",
            "Epoch 50/50\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.1039 - accuracy: 0.9612\n"
=======
            "108/108 [==============================] - 5s 5ms/step - loss: 0.6002 - accuracy: 0.7104\n",
            "Epoch 2/50\n",
            "108/108 [==============================] - 1s 6ms/step - loss: 0.3884 - accuracy: 0.8513\n",
            "Epoch 3/50\n",
            "108/108 [==============================] - 1s 8ms/step - loss: 0.2914 - accuracy: 0.8954\n",
            "Epoch 4/50\n",
            "108/108 [==============================] - 1s 9ms/step - loss: 0.2478 - accuracy: 0.9171\n",
            "Epoch 5/50\n",
            "108/108 [==============================] - 1s 10ms/step - loss: 0.2241 - accuracy: 0.9194\n",
            "Epoch 6/50\n",
            "108/108 [==============================] - 1s 10ms/step - loss: 0.2081 - accuracy: 0.9243\n",
            "Epoch 7/50\n",
            "108/108 [==============================] - 1s 8ms/step - loss: 0.1971 - accuracy: 0.9252\n",
            "Epoch 8/50\n",
            "108/108 [==============================] - 1s 7ms/step - loss: 0.1876 - accuracy: 0.9284\n",
            "Epoch 9/50\n",
            "108/108 [==============================] - 1s 10ms/step - loss: 0.1802 - accuracy: 0.9316\n",
            "Epoch 10/50\n",
            "108/108 [==============================] - 2s 21ms/step - loss: 0.1750 - accuracy: 0.9354\n",
            "Epoch 11/50\n",
            "108/108 [==============================] - 1s 13ms/step - loss: 0.1697 - accuracy: 0.9368\n",
            "Epoch 12/50\n",
            "108/108 [==============================] - 2s 16ms/step - loss: 0.1651 - accuracy: 0.9374\n",
            "Epoch 13/50\n",
            "108/108 [==============================] - 1s 11ms/step - loss: 0.1616 - accuracy: 0.9386\n",
            "Epoch 14/50\n",
            "108/108 [==============================] - 1s 6ms/step - loss: 0.1586 - accuracy: 0.9409\n",
            "Epoch 15/50\n",
            "108/108 [==============================] - 1s 8ms/step - loss: 0.1553 - accuracy: 0.9443\n",
            "Epoch 16/50\n",
            "108/108 [==============================] - 1s 10ms/step - loss: 0.1534 - accuracy: 0.9426\n",
            "Epoch 17/50\n",
            "108/108 [==============================] - 1s 10ms/step - loss: 0.1504 - accuracy: 0.9452\n",
            "Epoch 18/50\n",
            "108/108 [==============================] - 1s 9ms/step - loss: 0.1479 - accuracy: 0.9470\n",
            "Epoch 19/50\n",
            "108/108 [==============================] - 1s 6ms/step - loss: 0.1459 - accuracy: 0.9467\n",
            "Epoch 20/50\n",
            "108/108 [==============================] - 1s 6ms/step - loss: 0.1437 - accuracy: 0.9487\n",
            "Epoch 21/50\n",
            "108/108 [==============================] - 1s 5ms/step - loss: 0.1418 - accuracy: 0.9484\n",
            "Epoch 22/50\n",
            "108/108 [==============================] - 0s 3ms/step - loss: 0.1397 - accuracy: 0.9487\n",
            "Epoch 23/50\n",
            "108/108 [==============================] - 1s 5ms/step - loss: 0.1379 - accuracy: 0.9504\n",
            "Epoch 24/50\n",
            "108/108 [==============================] - 1s 6ms/step - loss: 0.1366 - accuracy: 0.9522\n",
            "Epoch 25/50\n",
            "108/108 [==============================] - 1s 8ms/step - loss: 0.1347 - accuracy: 0.9504\n",
            "Epoch 26/50\n",
            "108/108 [==============================] - 1s 8ms/step - loss: 0.1331 - accuracy: 0.9530\n",
            "Epoch 27/50\n",
            "108/108 [==============================] - 1s 11ms/step - loss: 0.1321 - accuracy: 0.9530\n",
            "Epoch 28/50\n",
            "108/108 [==============================] - 1s 11ms/step - loss: 0.1303 - accuracy: 0.9513\n",
            "Epoch 29/50\n",
            "108/108 [==============================] - 1s 12ms/step - loss: 0.1302 - accuracy: 0.9536\n",
            "Epoch 30/50\n",
            "108/108 [==============================] - 1s 8ms/step - loss: 0.1269 - accuracy: 0.9545\n",
            "Epoch 31/50\n",
            "108/108 [==============================] - 0s 4ms/step - loss: 0.1263 - accuracy: 0.9536\n",
            "Epoch 32/50\n",
            "108/108 [==============================] - 1s 5ms/step - loss: 0.1247 - accuracy: 0.9536\n",
            "Epoch 33/50\n",
            "108/108 [==============================] - 2s 16ms/step - loss: 0.1234 - accuracy: 0.9559\n",
            "Epoch 34/50\n",
            "108/108 [==============================] - 1s 11ms/step - loss: 0.1218 - accuracy: 0.9559\n",
            "Epoch 35/50\n",
            "108/108 [==============================] - 1s 9ms/step - loss: 0.1206 - accuracy: 0.9554\n",
            "Epoch 36/50\n",
            "108/108 [==============================] - 1s 6ms/step - loss: 0.1199 - accuracy: 0.9562\n",
            "Epoch 37/50\n",
            "108/108 [==============================] - 0s 4ms/step - loss: 0.1183 - accuracy: 0.9568\n",
            "Epoch 38/50\n",
            "108/108 [==============================] - 0s 4ms/step - loss: 0.1173 - accuracy: 0.9574\n",
            "Epoch 39/50\n",
            "108/108 [==============================] - 0s 4ms/step - loss: 0.1168 - accuracy: 0.9580\n",
            "Epoch 40/50\n",
            "108/108 [==============================] - 0s 4ms/step - loss: 0.1159 - accuracy: 0.9580\n",
            "Epoch 41/50\n",
            "108/108 [==============================] - 0s 3ms/step - loss: 0.1153 - accuracy: 0.9597\n",
            "Epoch 42/50\n",
            "108/108 [==============================] - 0s 3ms/step - loss: 0.1133 - accuracy: 0.9588\n",
            "Epoch 43/50\n",
            "108/108 [==============================] - 0s 3ms/step - loss: 0.1121 - accuracy: 0.9603\n",
            "Epoch 44/50\n",
            "108/108 [==============================] - 0s 4ms/step - loss: 0.1113 - accuracy: 0.9612\n",
            "Epoch 45/50\n",
            "108/108 [==============================] - 1s 6ms/step - loss: 0.1099 - accuracy: 0.9623\n",
            "Epoch 46/50\n",
            "108/108 [==============================] - 1s 6ms/step - loss: 0.1092 - accuracy: 0.9620\n",
            "Epoch 47/50\n",
            "108/108 [==============================] - 1s 6ms/step - loss: 0.1080 - accuracy: 0.9603\n",
            "Epoch 48/50\n",
            "108/108 [==============================] - 1s 5ms/step - loss: 0.1081 - accuracy: 0.9626\n",
            "Epoch 49/50\n",
            "108/108 [==============================] - 1s 7ms/step - loss: 0.1064 - accuracy: 0.9614\n",
            "Epoch 50/50\n",
            "108/108 [==============================] - 1s 10ms/step - loss: 0.1053 - accuracy: 0.9638\n"
>>>>>>> f3d0135c0960ed2272d2c7f47d9c9ed29bcb148c
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model using the test data\n",
        "model_loss, model_accuracy = nn_model1.evaluate(X_test_scaled,y_test,verbose=2)\n",
        "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r6l46OqakOLM",
<<<<<<< HEAD
        "outputId": "62e430fc-5fa7-47ad-d4f2-517b82415c08"
=======
        "outputId": "75f1c165-e314-45ad-9711-18899e823ecb"
>>>>>>> f3d0135c0960ed2272d2c7f47d9c9ed29bcb148c
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
<<<<<<< HEAD
            "36/36 - 0s - loss: 0.1701 - accuracy: 0.9435 - 263ms/epoch - 7ms/step\n",
            "Loss: 0.17007164657115936, Accuracy: 0.943527340888977\n"
=======
            "36/36 - 0s - loss: 0.1651 - accuracy: 0.9435 - 246ms/epoch - 7ms/step\n",
            "Loss: 0.16513986885547638, Accuracy: 0.943527340888977\n"
>>>>>>> f3d0135c0960ed2272d2c7f47d9c9ed29bcb148c
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Export our model to HDF5 file\n",
        "nn_model1.save('../h5_files/spamcsv_model_1.h5')"
      ],
      "metadata": {
        "id": "lKwBtYCokOFE"
      },
      "execution_count": 17,
<<<<<<< HEAD
=======
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nn_model2 = tf.keras.models.Sequential()\n",
        "input_features = X_train_scaled.shape[1]\n",
        "\n",
        "# First hidden layer\n",
        "nn_model2.add(tf.keras.layers.Dense(units=30, activation='tanh', input_dim=input_features))\n"
      ],
      "metadata": {
        "id": "xOrml5NGvqCH"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Second hidden layer\n",
        "nn_model2.add(tf.keras.layers.Dense(units=20, activation='tanh'))\n"
      ],
      "metadata": {
        "id": "M-L1FT8Lvp9W"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Output layer\n",
        "\n",
        "nn_model2.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))\n",
        "# Check the structure of the model\n",
        "nn_model2.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sADrvPrVvptg",
        "outputId": "627b6f61-11a7-4d22-c461-e4c6c3820f30"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_3 (Dense)             (None, 30)                1740      \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 20)                620       \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 1)                 21        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,381\n",
            "Trainable params: 2,381\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "nn_model2.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "T7UMv8zPxFOw"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "\n",
        "fit_model_2 = nn_model2.fit(X_train_scaled, y_train, epochs=50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nU8AKKksxLKP",
        "outputId": "941ebff4-862b-4c82-ac21-e34de8bc0eba"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "108/108 [==============================] - 2s 3ms/step - loss: 0.3661 - accuracy: 0.8606\n",
            "Epoch 2/50\n",
            "108/108 [==============================] - 0s 3ms/step - loss: 0.2272 - accuracy: 0.9217\n",
            "Epoch 3/50\n",
            "108/108 [==============================] - 0s 3ms/step - loss: 0.2018 - accuracy: 0.9243\n",
            "Epoch 4/50\n",
            "108/108 [==============================] - 0s 3ms/step - loss: 0.1887 - accuracy: 0.9316\n",
            "Epoch 5/50\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.1797 - accuracy: 0.9319\n",
            "Epoch 6/50\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.1732 - accuracy: 0.9342\n",
            "Epoch 7/50\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.1667 - accuracy: 0.9345\n",
            "Epoch 8/50\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.1622 - accuracy: 0.9380\n",
            "Epoch 9/50\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.1570 - accuracy: 0.9409\n",
            "Epoch 10/50\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.1535 - accuracy: 0.9414\n",
            "Epoch 11/50\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.1490 - accuracy: 0.9429\n",
            "Epoch 12/50\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.1462 - accuracy: 0.9449\n",
            "Epoch 13/50\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.1415 - accuracy: 0.9455\n",
            "Epoch 14/50\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.1388 - accuracy: 0.9478\n",
            "Epoch 15/50\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.1351 - accuracy: 0.9493\n",
            "Epoch 16/50\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.1315 - accuracy: 0.9481\n",
            "Epoch 17/50\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.1285 - accuracy: 0.9519\n",
            "Epoch 18/50\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.1252 - accuracy: 0.9516\n",
            "Epoch 19/50\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.1229 - accuracy: 0.9516\n",
            "Epoch 20/50\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.1194 - accuracy: 0.9528\n",
            "Epoch 21/50\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.1164 - accuracy: 0.9559\n",
            "Epoch 22/50\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.1146 - accuracy: 0.9577\n",
            "Epoch 23/50\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.1124 - accuracy: 0.9574\n",
            "Epoch 24/50\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.1078 - accuracy: 0.9571\n",
            "Epoch 25/50\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.1050 - accuracy: 0.9606\n",
            "Epoch 26/50\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.1018 - accuracy: 0.9632\n",
            "Epoch 27/50\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.1006 - accuracy: 0.9638\n",
            "Epoch 28/50\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0977 - accuracy: 0.9652\n",
            "Epoch 29/50\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0948 - accuracy: 0.9675\n",
            "Epoch 30/50\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0933 - accuracy: 0.9661\n",
            "Epoch 31/50\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0911 - accuracy: 0.9693\n",
            "Epoch 32/50\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0911 - accuracy: 0.9667\n",
            "Epoch 33/50\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0870 - accuracy: 0.9710\n",
            "Epoch 34/50\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0860 - accuracy: 0.9701\n",
            "Epoch 35/50\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0842 - accuracy: 0.9730\n",
            "Epoch 36/50\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0818 - accuracy: 0.9725\n",
            "Epoch 37/50\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0801 - accuracy: 0.9725\n",
            "Epoch 38/50\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0785 - accuracy: 0.9728\n",
            "Epoch 39/50\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0760 - accuracy: 0.9759\n",
            "Epoch 40/50\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0755 - accuracy: 0.9739\n",
            "Epoch 41/50\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0729 - accuracy: 0.9768\n",
            "Epoch 42/50\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0707 - accuracy: 0.9768\n",
            "Epoch 43/50\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0703 - accuracy: 0.9771\n",
            "Epoch 44/50\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0684 - accuracy: 0.9771\n",
            "Epoch 45/50\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0668 - accuracy: 0.9783\n",
            "Epoch 46/50\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0662 - accuracy: 0.9791\n",
            "Epoch 47/50\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0655 - accuracy: 0.9783\n",
            "Epoch 48/50\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0632 - accuracy: 0.9794\n",
            "Epoch 49/50\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0609 - accuracy: 0.9803\n",
            "Epoch 50/50\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0593 - accuracy: 0.9814\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model using the test data\n",
        "model_loss, model_accuracy = nn_model2.evaluate(X_test_scaled,y_test,verbose=2)\n",
        "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9bvgoD_Xxbev",
        "outputId": "390923e1-0d1c-42c5-c9c4-f9d2992e4afc"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "36/36 - 0s - loss: 0.1608 - accuracy: 0.9496 - 190ms/epoch - 5ms/step\n",
            "Loss: 0.16081812977790833, Accuracy: 0.9496090412139893\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Export our model to HDF5 file\n",
        "nn_model2.save('../h5_files/spamcsv_model_2.h5')"
      ],
      "metadata": {
        "id": "cwKxySYIxjER"
      },
      "execution_count": 24,
>>>>>>> f3d0135c0960ed2272d2c7f47d9c9ed29bcb148c
      "outputs": []
    }
  ]
}